# ============================================================
# CERTIFY INTEL - Environment Configuration
# ============================================================
# Copy this file to .env and fill in your values:
#
#   cp .env.example .env     (Linux/macOS)
#   copy .env.example .env   (Windows)
#
# REQUIRED: SECRET_KEY + ADMIN_PASSWORD + at least one AI provider key
# ============================================================


# --- SECURITY (REQUIRED) ---------------------------------------------------
# Generate a random key: python -c "import secrets; print(secrets.token_hex(32))"
SECRET_KEY=CHANGE-ME-generate-a-random-key


# --- ADMIN ACCOUNT (First Run) ---------------------------------------------
# These create the initial admin user on first startup.
# After first login you can change the password in Settings.
# If not set, defaults to: admin@certifyhealth.com / CertifyIntel2026!
ADMIN_EMAIL=admin@certifyhealth.com
ADMIN_PASSWORD=CertifyIntel2026!


# --- AI PROVIDERS (at least one required for AI features) -------------------

# Anthropic Claude (recommended primary - best quality for analysis)
# Get a key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# OpenAI GPT-4o (recommended fallback)
# Get a key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4.1

# Google Gemini (recommended for bulk/speed tasks - most cost effective)
# Get a key at: https://aistudio.google.com/apikey
GOOGLE_AI_API_KEY=
GOOGLE_AI_MODEL=gemini-3-flash-preview

# DeepSeek (optional - very cheap for bulk tasks)
DEEPSEEK_API_KEY=


# --- AI ROUTING (defaults work well for most setups) -----------------------
AI_PROVIDER=hybrid
AI_BULK_TASKS=gemini
AI_QUALITY_TASKS=anthropic
AI_FALLBACK_ENABLED=true


# --- OPTIONAL: Local AI (free, runs on your machine) -----------------------
# Ollama - run local LLMs at $0 cost (https://ollama.com)
OLLAMA_ENABLED=false
OLLAMA_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3.1:8b

# Local embeddings - free sentence-transformers (no API key needed)
USE_LOCAL_EMBEDDINGS=false


# --- OPTIONAL: AI Gateway ---------------------------------------------------
# LiteLLM - unified proxy for 100+ LLM providers (https://litellm.ai)
LITELLM_ENABLED=false
LITELLM_PROXY_URL=http://localhost:4000


# --- OPTIONAL: AI Evaluation ------------------------------------------------
# Opik - hallucination detection and groundedness scoring
OPIK_ENABLED=false


# --- OPTIONAL: Vertex AI (Google Cloud) -------------------------------------
VERTEX_AI_ENABLED=false
# VERTEX_AI_PROJECT=your-gcp-project
# VERTEX_AI_LOCATION=us-central1


# --- DATABASE ---------------------------------------------------------------
# Default: SQLite (no configuration needed, works out of the box)
# For PostgreSQL: uncomment and configure below
# DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/certify_intel


# --- OPTIONAL: Caching (Redis) ----------------------------------------------
REDIS_ENABLED=false
# REDIS_URL=redis://localhost:6379/0


# --- OPTIONAL: Observability ------------------------------------------------
# Langfuse - AI trace monitoring (https://langfuse.com)
# Requires Docker: docker compose -f docker-compose.langfuse.yml up -d
LANGFUSE_ENABLED=false
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
# LANGFUSE_HOST=http://localhost:3100

# Prometheus metrics endpoint
METRICS_ENABLED=false


# --- OPTIONAL: News Feed APIs (free tiers available) ------------------------
# GNEWS_API_KEY=          # gnews.io - 100 requests/day free
# MEDIASTACK_API_KEY=     # mediastack.com - 500/month free
# NEWSDATA_API_KEY=       # newsdata.io - 200/day free


# --- SECURITY & INFRASTRUCTURE ---------------------------------------------
SECURITY_HEADERS_ENABLED=true
RATE_LIMIT_ENABLED=true
JSON_LOGGING=false
ACCESS_TOKEN_EXPIRE_MINUTES=15
REFRESH_TOKEN_EXPIRE_DAYS=7
